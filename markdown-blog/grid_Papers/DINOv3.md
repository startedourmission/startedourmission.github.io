---
date: 2025-09-17
tags:
aliases:
image: Pasted image 20250917150521.png
---
>O. Siméoni et al., "DINOv3," arXiv preprint arXiv:2508.10104, 2025.

컴퓨터 비전 분야에서 라벨링 없이 강력한 특징을 학습할 수 있다면 어떨까요. Meta AI가 발표한 **DINOv3**는 자기지도학습(Self-Supervised Learning) 모델입니다. 70억 개의 파라미터를 가진 이 거대한 모델은 어떤 라벨도 없이 순수하게 이미지만으로 학습했지만 객체 탐지부터 깊이 추정까지 거의 모든 컴퓨터 비전 태스크에서 최고 수준의 성능을 달성했습니다.

![[Pasted image 20250917150521.png]]

# 요약

## 1. 모델 아키텍처

### 주요 모델 사양

|구성요소|DINOv2 (기존)|DINOv3 (신규)|
|---|---|---|
|**백본**|ViT-giant|ViT-7B|
|**파라미터 수**|1.1B|6.7B|
|**블록 수**|40|40|
|**패치 크기**|14×14|16×16|
|**위치 임베딩**|학습 가능|RoPE|
|**레지스터 토큰**|4개|4개|
|**임베딩 차원**|1,536|4,096|
|**FFN 숨은 차원**|4,096|8,192|
|**어텐션 헤드**|24개|32개|
|**헤드 차원**|64|128|

### 손실 함수 헤드 설정

- **DINO 헤드**: MLP 8192-8192-512, 프로토타입 256k개
- **iBOT 헤드**: MLP 8192-8192-384, 프로토타입 96k개

## 2. 훈련 데이터

### 데이터 구성 (총 16.89억 이미지)

1. **계층적 클러스터링 데이터**: DINOv2 임베딩 기반 5단계 클러스터링
    
    - 레벨별 클러스터 수: 200M → 8M → 800k → 100k → 25k
2. **검색 기반 큐레이션**: 시드 데이터셋과 유사한 이미지 검색
    
3. **검증된 데이터셋**: ImageNet1k, ImageNet22k, Mapillary
    

### 데이터 샘플링 전략

- **배치 구성**: 10% ImageNet1k 단독, 90% 혼합 배치
- **멀티크롭**: 글로벌 크롭 2개 (256px), 로컬 크롭 8개 (112px)

## 3. 훈련 설정

### 하드웨어 및 분산 설정

- **GPU**: 256개 GPU
- **배치 크기**: 4,096 이미지 (총)
- **시퀀스 길이**: 배치당 3.7M 토큰
- **옵티마이저**: AdamW

### 훈련 스케줄

- **1단계 사전훈련**: 1M 반복 (일정한 하이퍼파라미터)
- **2단계 Gram Anchoring**: 1M 반복 후 시작, 10k마다 교사 업데이트
- **3단계 고해상도 적응**: 10k 반복 (512-768px 혼합 해상도)

### 주요 하이퍼파라미터

- **학습률**: 일정 (워밍업 후)
- **가중치 감쇠**: 일정
- **교사 EMA 모멘텀**: 일정
- **Koleo 가중치**: 0.1

## 4. Gram Anchoring 세부사항

### Gram 손실 계산

```
L_Gram = ||X_S · X_S^T - X_G · X_G^T||_F^2
```

- **X_S**: 학생 네트워크의 정규화된 패치 특징 (P × d)
- **X_G**: Gram 교사의 정규화된 패치 특징 (P × d)
- **적용 시점**: 1M 반복 후
- **교사 업데이트**: 10k 반복마다

### 고해상도 Gram Anchoring

- **교사 해상도**: 2배 높은 해상도 (512px)
- **다운샘플링**: 바이큐빅 보간으로 2배 축소
- **성능 향상**: ADE20k에서 +2 mIoU 추가 개선

## 5. 모델 증류

### 멀티스튜던트 증류 파이프라인

- **교사**: 고정된 7B 모델
- **학생 모델들**: ViT-S (21M), ViT-B (86M), ViT-L (300M), ViT-H+ (800M)
- **훈련 시간**: 1M 반복 + 250k 쿨다운

### 효율적 증류 전략

- 교사 추론을 모든 GPU에서 공유
- 학생별로 별도 GPU 그룹 할당
- 반복 시간 동기화로 대기 시간 최소화

## 6. 평가 설정

### 조밀 특징 평가

- **해상도**: 1024 패치 토큰 기준
    - 패치 14: 448×448px
    - 패치 16: 512×512px
- **세그멘테이션**: 선형 프로빙 (frozen backbone)
- **깊이 추정**: 선형 프로빙 (frozen backbone)

### 글로벌 특징 평가

- **분류**: ImageNet 선형 프로빙
- **OOD 평가**: ObjectNet, ImageNet-R/A/S 등
- **검색**: 코사인 유사도 기반 비모수적 검색

### 복합 시스템 평가

- **객체 탐지**: Plain-DETR + frozen DINOv3
- **세그멘테이션**: Mask2Former + ViT-Adapter + frozen DINOv3
- **깊이 추정**: DPT + frozen DINOv3

## 7. 주요 성능 지표

### 조밀 특징 성능

- **ADE20k 세그멘테이션**: 55.9 mIoU (선형 프로빙)
- **NYUv2 깊이**: 0.309 RMSE
- **NAVI 3D 매칭**: 64.4% 리콜

### 글로벌 특징 성능

- **ImageNet 분류**: 88.4% (선형 프로빙)
- **ObjectNet OOD**: 79.0%
- **Oxford-H 검색**: 60.7 mAP

### 실제 시스템 성능

- **COCO 객체 탐지**: 66.1 mAP (frozen backbone)
- **ADE20k 세그멘테이션**: 63.0 mIoU (전체 시스템)
- **깊이 추정**: 5개 데이터셋 모두 SOTA 달성

## 8. 텍스트 정렬 설정

### LiT 기반 훈련

- **비전 백본**: 완전 동결
- **텍스트 인코더**: 처음부터 훈련
- **추가 레이어**: 2개 트랜스포머 레이어
- **특징 결합**: CLS 토큰 + 평균 풀링된 패치 임베딩

### 데이터 큐레이션

- Jose et al. (2025)와 동일한 프로토콜 사용
- 대조 학습 목적함수로 이미지-캡션 쌍 학습

## 9. 특수 기법들

### RoPE 박스 지터링

- **좌표 박스**: [-1, 1]을 [-s, s]로 랜덤 스케일링
- **스케일 범위**: s ∈ [0.5, 2]
- **목적**: 해상도, 스케일, 종횡비에 대한 강건성 향상

### 레지스터 토큰

- **개수**: 4개
- **목적**: 고노름 패치 이상값 방지
- **DINOv2에서 이어받은 기법**: 패치 노름 안정성 유지

### 분산 Koleo 정규화

- **배치 크기**: 16 샘플 (GPU 간 분산)
- **목적**: 배치 내 특징의 균등 분포 유도
- **가중치**: 0.1

## 10. 재현성 정보

### 코드 및 모델 공개

- **모든 모델 가중치**: 공개 예정
- **훈련 코드**: 상세 하이퍼파라미터와 함께 공개
- **평가 프로토콜**: 벤치마크별 상세 설정 제공

### 하드웨어 요구사항

- **최소 GPU 메모리**: 7B 모델 추론 시 24GB+ 권장
- **훈련**: 256 GPU × 수주간 (70억 파라미터 기준)
- **증류 모델**: 단일 GPU에서도 실행 가능 (ViT-S/B)

# 논문 상세

### 1. 70억 파라미터 모델

DINOv3의 가장 눈에 띄는 특징은 규모입니다. 이전 버전인 DINOv2의 11억 파라미터에서 무려 **70억 파라미터**로 대폭 확장했습니다. 하지만 단순히 모델을 키운 것이 아닙니다.

**DINOv2 대비 아키텍처 개선**:

- **RoPE(Rotary Position Embedding)**: 다양한 해상도와 종횡비에 강건한 위치 임베딩
- **패치 크기 변경**: 14×14에서 16×16으로 변경하여 동일한 시퀀스 길이로 더 높은 해상도 처리
- **차원 확장**: 임베딩 차원을 1536에서 4096으로 확장

### 2. 데이터 큐레이션

DINOv3는 Instagram의 170억 이미지 풀에서 시작하여 세심하게 큐레이션된 16.89억 이미지로 훈련되었습니다:

**3가지 데이터 구성 전략**:

- **계층적 클러스터링**: DINOv2 임베딩을 활용한 5단계 클러스터링으로 시각적 개념의 균형잡힌 커버리지 확보
- **검색 기반 큐레이션**: 다운스트림 태스크와 관련된 시드 데이터셋과 유사한 이미지 검색
- **고품질 데이터셋**: ImageNet1k, ImageNet22k, Mapillary 등 검증된 데이터셋 혼합

**스마트한 배치 전략**: 각 배치의 10%는 ImageNet1k만으로, 나머지 90%는 모든 데이터 소스를 혼합하여 구성

### 3. Gram Anchoring

DINOv3의 가장 혁신적인 기술적 성과는 **Gram Anchoring**입니다. 이는 대규모 모델의 훈련이 진행될수록 패치 레벨 특징이 일관성을 잃는 문제를 해결합니다.

**문제 인식**:

- 글로벌 성능은 계속 향상되지만 조밀 예측 태스크(세그멘테이션, 깊이 추정) 성능은 오히려 악화
- 패치 간 코사인 유사도가 노이즈가 많아지고 지역성이 사라짐

**Gram Anchoring 솔루션**:

```
L_Gram = ||X_S · X_S^T - X_G · X_G^T||_F^2
```

여기서 X_S는 학생 네트워크의 패치 특징, X_G는 초기 단계 교사 네트워크의 패치 특징입니다.

**핵심 아이디어**: 특징 자체가 아닌 패치 간 유사도 구조(Gram 행렬)를 보존하여 지역 일관성을 유지

## 훈련 전략

### 1. 일정한 하이퍼파라미터 스케줄링

기존의 코사인 스케줄링을 버리고 **일정한 학습률, 가중치 감쇠, 교사 EMA 모멘텀**을 사용:

- 최적화 지평선을 미리 설정할 필요 없음
- 성능이 향상되는 한 무한정 훈련 가능
- 하이퍼파라미터 수 감소로 튜닝 용이성 증대

### 2. 멀티스케일 고해상도 적응

256픽셀로 사전 훈련 후 512-768픽셀로 고해상도 적응:

- 실제 응용에서 요구되는 다양한 해상도에 대응
- Gram Anchoring을 고해상도 적응에도 적용
- 최대 4096픽셀까지 안정적인 특징 맵 제공

### 3. 혁신적인 멀티스튜던트 증류

하나의 70억 파라미터 교사 모델에서 여러 크기의 학생 모델을 동시에 증류:

- ViT-S (21M), ViT-B (86M), ViT-L (300M), ViT-H+ (800M)
- 교사 추론 비용을 모든 GPU에서 공유하여 효율성 극대화
- 각 학생의 반복 시간을 동일하게 맞춰 대기 시간 최소화

## 압도적인 성능 결과

### 조밀 특징의 우월성

**세그멘테이션 (선형 프로빙)**:

- ADE20k: 55.9 mIoU (이전 최고 대비 +6.4)
- Cityscapes: 81.1 mIoU (+5.5)
- VOC: 86.6 mIoU

**깊이 추정**:

- NYUv2: 0.309 RMSE (DINOv2 대비 0.063 개선)
- KITTI: 2.346 RMSE (0.278 개선)

**3D 대응점 매칭**:

- NAVI: 64.4% 리콜 (DINOv2 대비 +4.3%)
- SPair: 58.7% 리콜 (+2.6%)

### 글로벌 특징의 강건성

**ImageNet 분류 및 OOD 성능**:

- ImageNet: 88.4% (약지도 모델 수준)
- ObjectNet: 79.0% (DINOv2 대비 +12.6%)
- ImageNet-R: 91.1% (+10%)
- ImageNet-A: 86.9% (+5.2%)

**실제 시스템에서의 SOTA 달성**:

- **객체 탐지** (COCO): 66.1 mAP (frozen backbone으로!)
- **세그멘테이션** (ADE20k): 63.0 mIoU (ONE-PEACE와 동일)
- **깊이 추정**: 5개 데이터셋 모두에서 새로운 최고 성능

## 실용적 가치와 영향

### 1. Frozen Backbone의 힘

DINOv3의 가장 인상적인 특징 중 하나는 **백본을 동결한 상태**에서도 최고 수준의 성능을 달성한다는 점입니다:

- 단일 포워드 패스로 여러 태스크 처리 가능
- 계산 비용 대폭 절약
- 에지 디바이스에서의 실용적 활용 가능

### 2. 도메인 적응성

자연 이미지뿐만 아니라 다양한 도메인에서 뛰어난 성능:

- 위성 이미지 분석
- 의료 영상 처리
- 역사적 이미지 검색
- 예술 작품 분석

### 3. 과학적 응용 가능성

라벨이 없는 관측 데이터가 풍부한 과학 분야에서의 활용:

- 조직병리학 (histopathology)
- 생물학 연구
- 의료 영상
- 원격 감지
- 천문학
- 고에너지 입자 물리학

## 기술적 혁신의 깊이

### 1. 손실 함수 설계

```
L_Pre = L_DINO + L_iBOT + 0.1 * L_DKoleo
L_Ref = w_D * L_DINO + L_iBOT + w_DK * L_DKoleo + w_Gram * L_Gram
```

- **L_DINO**: 이미지 레벨 판별적 자기지도 목적함수
- **L_iBOT**: 패치 레벨 잠재 재구성 목적함수
- **L_DKoleo**: 배치 내 특징이 공간에서 균등하게 분포하도록 하는 정규화
- **L_Gram**: 패치 간 유사도 구조 보존을 위한 새로운 목적함수

### 2. 고해상도 Gram Anchoring

단순한 Gram Anchoring을 넘어 고해상도 특징을 활용:

- 2배 높은 해상도에서 Gram 교사 특징 추출
- 바이큐빅 보간으로 다운샘플링하여 더 부드러운 특징 맵 획득
- ADE20k에서 추가 +2 mIoU 성능 향상

### 3. 텍스트 정렬 확장

LiT(Locked-image Text Tuning) 패러다임을 활용한 제로샷 멀티모달 능력:

- 비전 백본은 동결하고 텍스트 인코더만 훈련
- CLS 토큰과 평균 풀링된 패치 임베딩 결합
- 글로벌과 지역 시각 특징을 모두 텍스트와 정렬

## 한계와 미래 과제

### 현재의 한계점

1. **계산 자원 요구량**: 70억 파라미터 모델의 훈련과 추론 비용
2. **데이터 의존성**: 고품질 큐레이션된 데이터에 대한 의존
3. **특정 도메인 성능**: 일부 전문 도메인에서는 여전히 특화 모델이 우세

### 미래 연구 방향

1. **더 효율적인 아키텍처**: 성능을 유지하면서 계산 효율성을 높이는 방법
2. **자동 데이터 큐레이션**: 인간 개입 없이 고품질 훈련 데이터 자동 선별
3. **멀티모달 확장**: 비디오, 오디오 등 다른 모달리티와의 통합
4. **온라인 학습**: 지속적으로 새로운 데이터로 학습하는 평생학습 시스템