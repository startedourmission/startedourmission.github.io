---
date: 2025-09-17
tags:
aliases:
  - 언어 모델 환각은 왜 생기는가
image: "![[Hallucinate_1.png]]"
---
대형 언어모델(LLM)이 점점 더 우리 일상에 자리잡고 있지만 여전히 해결되지 않은 문제가 있습니다. 바로 **환각(hallucination)** 현상입니다. 모델이 그럴듯해 보이지만 사실과 다른 정보를 마치 확신에 차서 제공하는 현상 말입니다. OpenAI의 Adam Kalai와 동료들이 발표한 이 논문은 단순히 "환각이 왜 생기는가?"를 넘어서 "왜 환각이 계속 남아있는가?"까지 깊이 있게 분석합니다.

> A. T. Kalai, O. Nachum, S. S. Vempala, and E. Zhang, "Why Language Models Hallucinate", arXiv preprint arXiv:2509.04664, 2024.

머리말을 읽으면서 흥미로웠던 점은 환각을 시험을 보는 학생의 추측에 비유한 것입니다. 불확실할 때 "모르겠다"고 하는 대신 그럴듯한 답을 지어내는 것이죠.

![[Hallucinate_1.png]]
# 요약

이 연구는 언어모델의 환각 현상을 통계적 관점에서 체계적으로 분석합니다. 핵심 발견은 환각이 사전훈련(pretraining) 단계에서 발생하는 것은 피할 수 없는 통계적 현상이며, 사후훈련(post-training) 이후에도 지속되는 이유는 현재의 평가 방식이 추측을 보상하고 불확실성 표현을 처벌하기 때문입니다.

**주요 기술적 내용:**

- **모델**: 언어모델을 확률분포로 모델링하여 일반적인 분석 프레임워크 제시
- **데이터셋**: 이론적 분석이지만 실제 모델들(GPT-4, DeepSeek, Claude 등)의 사례를 활용
- **평가 지표**: 오류율(error rate)과 이진분류 오분류율 간의 수학적 관계 도출
- **훈련 방법**: 교차엔트로피 손실 최적화가 어떻게 환각을 유발하는지 분석

# 논문 상세

## 1. 서론

연구진은 환각을 단순한 버그가 아닌 현재 언어모델 훈련 패러다임의 필연적 결과로 봅니다. 특히 "Adam Tauman Kalai의 생일이 언제인가?"라는 질문에 최신 모델이 세 번 다른 틀린 답을 한 사례를 제시하며, 이것이 개별 모델의 문제가 아님을 보여줍니다.

## 2. 사전훈련에서 발생하는 오류

### 2.1 Is-It-Valid (IIV) 감축 이론

논문의 핵심 이론적 기여는 생성적 오류와 이진분류 오류를 연결하는 것입니다. 연구진은 "이것이 유효한 언어모델 출력인가?"라는 이진분류 문제(IIV)를 정의하고, 다음과 같은 부등식을 도출했습니다:

$$\text{생성 오류율} \geq 2 \times \text{IIV 오분류율}$$

이는 언어모델이 유효한 출력을 생성하는 것이 유효성을 판별하는 것보다 본질적으로 어렵다는 것을 의미합니다.

### 2.2 임의 사실 환각

특히 흥미로운 부분은 "임의 사실(arbitrary facts)" 분석입니다. 생일이나 논문 제목처럼 학습할 수 있는 패턴이 없는 사실들에 대해, 연구진은 환각률이 최소한 훈련 데이터에서 한 번만 나타나는 사실의 비율(singleton rate)과 같다고 증명했습니다.

임의 사실 모델에서 어떤 알고리즘이든 99% 확률로 다음을 만족합니다:

$$\text{err} \geq \text{sr} - \frac{2}{\min_c |E_c|} - \frac{35 + 6\ln N}{\sqrt{N}} - \delta$$

여기서 $\text{sr}$은 singleton rate, $N$은 훈련 샘플 수입니다.

### 2.3 부실한 모델

환각은 모델 자체의 한계에서도 발생합니다. 예를 들어, "DEEPSEEK"에서 D가 몇 개인지 세는 문제에서 많은 모델이 틀린 답을 하는데, 이는 토큰 기반 표현의 한계 때문입니다. 반면 추론(reasoning) 모델은 이런 문제를 단계별로 풀어서 정확한 답을 제공합니다.

## 3. 사후훈련에서 환각의 지속

### 3.1 평가가 환각을 강화하는 방식

논문은 현재의 이진 평가 방식이 환각을 조장한다고 주장합니다. 대부분의 벤치마크가 정답/오답 방식으로 채점하며, **"모르겠다"는 답에는 0점을 주기 때문에**, 모델은 불확실할 때도 추측하는 것이 유리합니다. 

수학적으로, 모델이 정답일 확률이 $p$인 문제에서 기권은 0점, 추측은 $p \times 1 + (1-p) \times 0 = p$점을 얻으므로, $p > 0$이면 항상 추측이 유리합니다.

### 3.2 명시적 신뢰도 목표

연구진은 해결책으로 평가에서 명시적 신뢰도 임계값을 제시할 것을 제안합니다:

> "당신이 $t$ 이상 확신할 때만 답하세요. 틀린 답은 $\frac{t}{1-t}$점을 감점하고, 정답은 1점, '모르겠다'는 0점입니다."

이렇게 하면 모델은 자신의 확신도에 따라 적절히 기권할 수 있습니다.

## 4. 현재 평가 방식의 문제점

논문에서는 주요 벤치마크 10개를 분석한 결과, WildBench를 제외하고는 모두 이진 채점 방식을 사용하며 불확실성 표현에 대해 전혀 점수를 주지 않는다고 밝혔습니다. 이는 아무리 좋은 환각 탐지 방법을 개발해도 주요 평가에서 불리해지는 구조적 문제를 만듭니다.

## 5. 한계와 확장성

연구진은 자신들의 프레임워크가 몇 가지 한계가 있음을 인정합니다. 열린 생성 태스크나 정도의 차이가 있는 환각, 맥락에 따라 달라질 수 있는 오류 등은 현재 모델에서 완전히 다루지 못합니다. 이어 검색이나 추론을 통한 확장도 근본적인 해결책이 되지는 못한다고 지적합니다.

## 결론

이 논문은 환각 현상을 두 단계로 나누어 설명합니다. 사전훈련에서는 통계적 필연성으로, 사후훈련 이후에는 평가 시스템의 구조적 문제로 환각이 지속됩니다. 특히 평가 방식을 바꾸는 것만으로도 상당한 개선이 가능하다는 제안은 중요한 시사점입니다. 결국 더 신뢰할 만한 AI 시스템을 만들기 위해서는 기술적 개선과 함께 평가 문화의 변화도 필요하다는 이야기입니다. 